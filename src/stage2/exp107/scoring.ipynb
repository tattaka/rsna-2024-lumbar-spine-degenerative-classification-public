{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "import sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_condition(full_location: str) -> str:\n",
    "    # Given an input like spinal_canal_stenosis_l1_l2 extracts 'spinal'\n",
    "    for injury_condition in ['spinal', 'foraminal', 'subarticular']:\n",
    "        if injury_condition in full_location:\n",
    "            return injury_condition\n",
    "    raise ValueError(f'condition not found in {full_location}')\n",
    "\n",
    "\n",
    "def score(\n",
    "        solution: pd.DataFrame,\n",
    "        submission: pd.DataFrame,\n",
    "        row_id_column_name: str,\n",
    "        any_severe_scalar: float\n",
    "    ) -> float:\n",
    "    '''\n",
    "    Pseudocode:\n",
    "    1. Calculate the sample weighted log loss for each medical condition:\n",
    "    2. Derive a new any_severe label.\n",
    "    3. Calculate the sample weighted log loss for the new any_severe label.\n",
    "    4. Return the average of all of the label group log losses as the final score, normalized for the number of columns in each group.\n",
    "       This mitigates the impact of spinal stenosis having only half as many columns as the other two conditions.\n",
    "    '''\n",
    "\n",
    "    target_levels = ['normal_mild', 'moderate', 'severe']\n",
    "\n",
    "    # Run basic QC checks on the inputs\n",
    "    if not pandas.api.types.is_numeric_dtype(submission[target_levels].values):\n",
    "        raise ParticipantVisibleError('All submission values must be numeric')\n",
    "\n",
    "    if not np.isfinite(submission[target_levels].values).all():\n",
    "        raise ParticipantVisibleError('All submission values must be finite')\n",
    "\n",
    "    if solution[target_levels].min().min() < 0:\n",
    "        raise ParticipantVisibleError('All labels must be at least zero')\n",
    "    if submission[target_levels].min().min() < 0:\n",
    "        raise ParticipantVisibleError('All predictions must be at least zero')\n",
    "\n",
    "    solution['study_id'] = solution['row_id'].apply(lambda x: x.split('_')[0])\n",
    "    solution['location'] = solution['row_id'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "    solution['condition'] = solution['row_id'].apply(get_condition)\n",
    "\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "    assert sorted(submission.columns) == sorted(target_levels)\n",
    "\n",
    "    submission['study_id'] = solution['study_id']\n",
    "    submission['location'] = solution['location']\n",
    "    submission['condition'] = solution['condition']\n",
    "\n",
    "    # condition_losses = []\n",
    "    # condition_weights = []\n",
    "    # for condition in ['spinal', 'foraminal', 'subarticular']:\n",
    "    #     condition_indices = solution.loc[solution['condition'] == condition].index.values\n",
    "    #     condition_loss = sklearn.metrics.log_loss(\n",
    "    #         y_true=solution.loc[condition_indices, target_levels].values,\n",
    "    #         y_pred=submission.loc[condition_indices, target_levels].values,\n",
    "    #         sample_weight=solution.loc[condition_indices, 'sample_weight'].values\n",
    "    #     )\n",
    "    #     condition_losses.append(condition_loss)\n",
    "    #     condition_weights.append(1)\n",
    "\n",
    "    condition_losses = {}\n",
    "    condition_weights = {}\n",
    "    for condition in ['spinal', 'foraminal', 'subarticular']:\n",
    "        condition_indices = solution.loc[solution['condition'] == condition].index.values\n",
    "        condition_loss = sklearn.metrics.log_loss(\n",
    "            y_true=solution.loc[condition_indices, target_levels].values,\n",
    "            y_pred=submission.loc[condition_indices, target_levels].values,\n",
    "            sample_weight=solution.loc[condition_indices, 'sample_weight'].values\n",
    "        )\n",
    "        condition_losses[condition] = condition_loss\n",
    "        condition_weights[condition] = 1\n",
    "\n",
    "    any_severe_spinal_labels = pd.Series(solution.loc[solution['condition'] == 'spinal'].groupby('study_id')['severe'].max())\n",
    "    any_severe_spinal_weights = pd.Series(solution.loc[solution['condition'] == 'spinal'].groupby('study_id')['sample_weight'].max())\n",
    "    any_severe_spinal_predictions = pd.Series(submission.loc[submission['condition'] == 'spinal'].groupby('study_id')['severe'].max())\n",
    "    any_severe_spinal_loss = sklearn.metrics.log_loss(\n",
    "        y_true=any_severe_spinal_labels,\n",
    "        y_pred=any_severe_spinal_predictions,\n",
    "        sample_weight=any_severe_spinal_weights\n",
    "    )\n",
    "    condition_losses[\"any\"]=any_severe_spinal_loss\n",
    "    condition_weights[\"any\"] = any_severe_scalar\n",
    "    return np.average(np.asarray(list(condition_losses.values())), weights=np.asarray(list(condition_weights.values()))), condition_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>normal_mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100206310_left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.683105</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.016098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100206310_left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.402588</td>\n",
       "      <td>0.553223</td>\n",
       "      <td>0.044159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100206310_left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.148315</td>\n",
       "      <td>0.727539</td>\n",
       "      <td>0.124146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100206310_left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.507324</td>\n",
       "      <td>0.420410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100206310_left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.269531</td>\n",
       "      <td>0.643066</td>\n",
       "      <td>0.087280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            row_id  normal_mild  moderate  \\\n",
       "0  100206310_left_neural_foraminal_narrowing_l1_l2     0.683105  0.300781   \n",
       "1  100206310_left_neural_foraminal_narrowing_l2_l3     0.402588  0.553223   \n",
       "2  100206310_left_neural_foraminal_narrowing_l3_l4     0.148315  0.727539   \n",
       "3  100206310_left_neural_foraminal_narrowing_l4_l5     0.072266  0.507324   \n",
       "4  100206310_left_neural_foraminal_narrowing_l5_s1     0.269531  0.643066   \n",
       "\n",
       "     severe  \n",
       "0  0.016098  \n",
       "1  0.044159  \n",
       "2  0.124146  \n",
       "3  0.420410  \n",
       "4  0.087280  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"eval_rdnet_tiny_ax5ch_mask0.1.csv\").sort_values(\"row_id\", ascending=True).reset_index(drop=True).copy()\n",
    "\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>normal_mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>severe</th>\n",
       "      <th>sample_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100206310</td>\n",
       "      <td>100206310_left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100206310</td>\n",
       "      <td>100206310_left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100206310</td>\n",
       "      <td>100206310_left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100206310</td>\n",
       "      <td>100206310_left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100206310</td>\n",
       "      <td>100206310_left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    study_id                                           row_id  normal_mild  \\\n",
       "0  100206310  100206310_left_neural_foraminal_narrowing_l1_l2          1.0   \n",
       "1  100206310  100206310_left_neural_foraminal_narrowing_l2_l3          0.0   \n",
       "2  100206310  100206310_left_neural_foraminal_narrowing_l3_l4          0.0   \n",
       "3  100206310  100206310_left_neural_foraminal_narrowing_l4_l5          0.0   \n",
       "4  100206310  100206310_left_neural_foraminal_narrowing_l5_s1          0.0   \n",
       "\n",
       "   moderate  severe  sample_weight  \n",
       "0       0.0     0.0            1.0  \n",
       "1       1.0     0.0            2.0  \n",
       "2       1.0     0.0            2.0  \n",
       "3       0.0     1.0            4.0  \n",
       "4       1.0     0.0            2.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_main = pd.read_csv(\"../../../input/rsna-2024-lumbar-spine-degenerative-classification/train.csv\")\n",
    "\n",
    "solution = train_main.melt(id_vars=[\"study_id\"], var_name=\"full_label\", value_name=\"severity\")\n",
    "solution[\"row_id\"] = solution.apply(lambda row: str(row.study_id) + \"_\" + row.full_label, axis=1)\n",
    "solution.severity = solution.severity.fillna(\"Normal/Mild\")\n",
    "solution.loc[solution.severity == \"Normal/Mild\", \"normal_mild\"] = 1\n",
    "solution.loc[solution.severity == \"Moderate\", \"moderate\"] = 1\n",
    "solution.loc[solution.severity == \"Severe\", \"severe\"] = 1\n",
    "\n",
    "solution.loc[solution.severity == \"Normal/Mild\", \"sample_weight\"] = 1\n",
    "solution.loc[solution.severity == \"Moderate\", \"sample_weight\"] = 2\n",
    "solution.loc[solution.severity == \"Severe\", \"sample_weight\"] = 4\n",
    "\n",
    "solution = solution[[\"study_id\", \"row_id\", \"normal_mild\", \"moderate\", \"severe\", \"sample_weight\"]]\n",
    "solution = solution.fillna(0)\n",
    "solution = solution.sort_values(by=[\"row_id\"])\n",
    "solution = solution[solution[\"row_id\"].isin(submission.row_id)].sort_values(\"row_id\", ascending=True).reset_index(drop=True).copy()\n",
    "\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = solution[[\"row_id\", \"normal_mild\", \"moderate\", \"severe\", \"sample_weight\"]]\n",
    "solution.head()\n",
    "solution = solution.sort_values(\"row_id\", ascending=True).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Score (0.42509585398557415, {'spinal': 0.3007977998216565, 'foraminal': 0.5152693856954428, 'subarticular': 0.5926139075340882, 'any': 0.291702322891109})\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = score(solution.copy(), submission.copy(), \"row_id\", 1)\n",
    "f\"Score {s}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Score (0.42509585398557415, {'spinal': 0.3007977998216565, 'foraminal': 0.5152693856954428, 'subarticular': 0.5926139075340882, 'any': 0.291702322891109})\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = score(solution.sort_values(\"row_id\").copy(), submission.sort_values(\"row_id\").copy(), \"row_id\", 1)\n",
    "f\"Score {s}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Score (0.42509585398557415, {'spinal': 0.3007977998216565, 'foraminal': 0.5152693856954428, 'subarticular': 0.5926139075340882, 'any': 0.291702322891109})\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = score(solution.sort_values(\"row_id\", ascending=True).copy(), submission.sort_values(\"row_id\", ascending=False).copy(), \"row_id\", 1)\n",
    "f\"Score {s}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Score (0.42509585398557415, {'spinal': 0.3007977998216565, 'foraminal': 0.5152693856954427, 'subarticular': 0.5926139075340884, 'any': 0.291702322891109})\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "s = score(solution.sort_values(\"row_id\", ascending=False).copy(), submission.sort_values(\"row_id\", ascending=True).copy(), \"row_id\", 1)\n",
    "f\"Score {s}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>normal_mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>severe</th>\n",
       "      <th>sample_weight</th>\n",
       "      <th>fold_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004726367</td>\n",
       "      <td>1004726367_left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004726367</td>\n",
       "      <td>1004726367_left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004726367</td>\n",
       "      <td>1004726367_left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004726367</td>\n",
       "      <td>1004726367_left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004726367</td>\n",
       "      <td>1004726367_left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     study_id                                            row_id  normal_mild  \\\n",
       "0  1004726367  1004726367_left_neural_foraminal_narrowing_l1_l2          1.0   \n",
       "1  1004726367  1004726367_left_neural_foraminal_narrowing_l2_l3          1.0   \n",
       "2  1004726367  1004726367_left_neural_foraminal_narrowing_l3_l4          1.0   \n",
       "3  1004726367  1004726367_left_neural_foraminal_narrowing_l4_l5          1.0   \n",
       "4  1004726367  1004726367_left_neural_foraminal_narrowing_l5_s1          1.0   \n",
       "\n",
       "   moderate  severe  sample_weight  fold_id  \n",
       "0       0.0     0.0            1.0        0  \n",
       "1       0.0     0.0            1.0        0  \n",
       "2       0.0     0.0            1.0        0  \n",
       "3       0.0     0.0            1.0        0  \n",
       "4       0.0     0.0            1.0        0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    \"../../../input/rsna-2024-lumbar-spine-degenerative-classification/train.csv\"\n",
    ")\n",
    "train_df[\"fold_id\"] = -1\n",
    "for i, (train_index, valid_index) in enumerate(\n",
    "    GroupKFold(n_splits=5).split(\n",
    "        train_df, np.arange(len(train_df)), train_df.study_id\n",
    "    )\n",
    "):\n",
    "    train_df.loc[valid_index, \"fold_id\"] = i\n",
    "\n",
    "\n",
    "solution = train_main.melt(id_vars=[\"study_id\"], var_name=\"full_label\", value_name=\"severity\")\n",
    "solution[\"row_id\"] = solution.apply(lambda row: str(row.study_id) + \"_\" + row.full_label, axis=1)\n",
    "solution.severity = solution.severity.fillna(\"Normal/Mild\")\n",
    "solution.loc[solution.severity == \"Normal/Mild\", \"normal_mild\"] = 1\n",
    "solution.loc[solution.severity == \"Moderate\", \"moderate\"] = 1\n",
    "solution.loc[solution.severity == \"Severe\", \"severe\"] = 1\n",
    "\n",
    "solution.loc[solution.severity == \"Normal/Mild\", \"sample_weight\"] = 1\n",
    "solution.loc[solution.severity == \"Moderate\", \"sample_weight\"] = 2\n",
    "solution.loc[solution.severity == \"Severe\", \"sample_weight\"] = 4\n",
    "\n",
    "solution = solution[[\"study_id\", \"row_id\", \"normal_mild\", \"moderate\", \"severe\", \"sample_weight\"]]\n",
    "solution = solution.fillna(0)\n",
    "solution = solution.sort_values(by=[\"row_id\"])\n",
    "solution = solution[solution[\"row_id\"].isin(submission.row_id)].sort_values(\"row_id\", ascending=True).reset_index(drop=True).copy()\n",
    "\n",
    "solution = solution.merge(train_df[[\"study_id\", \"fold_id\"]], on=\"study_id\")\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (0.43863528103753635, {'spinal': 0.3039514215893382, 'foraminal': 0.5309460217058181, 'subarticular': 0.6292125137597322, 'any': 0.2904311670952572})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution\u001b[49m\u001b[43m[\u001b[49m\u001b[43msolution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmission\u001b[49m\u001b[43m[\u001b[49m\u001b[43msolution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrow_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 70\u001b[0m, in \u001b[0;36mscore\u001b[0;34m(solution, submission, row_id_column_name, any_severe_scalar)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m condition \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspinal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforaminal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubarticular\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     69\u001b[0m     condition_indices \u001b[38;5;241m=\u001b[39m solution\u001b[38;5;241m.\u001b[39mloc[solution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m condition]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m---> 70\u001b[0m     condition_loss \u001b[38;5;241m=\u001b[39m \u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcondition_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_levels\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubmission\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcondition_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_levels\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcondition_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     condition_losses[condition] \u001b[38;5;241m=\u001b[39m condition_loss\n\u001b[1;32m     76\u001b[0m     condition_weights[condition] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2587\u001b[0m, in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_loss\u001b[39m(\n\u001b[1;32m   2510\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2511\u001b[0m ):\n\u001b[1;32m   2512\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Log loss, aka logistic loss or cross-entropy loss.\u001b[39;00m\n\u001b[1;32m   2513\u001b[0m \n\u001b[1;32m   2514\u001b[0m \u001b[38;5;124;03m    This is the loss function used in (multinomial) logistic regression\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2585\u001b[0m \u001b[38;5;124;03m    0.21616...\u001b[39;00m\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2587\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2588\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2590\u001b[0m     eps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(y_pred\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39meps \u001b[38;5;28;01mif\u001b[39;00m eps \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m eps\n\u001b[1;32m   2592\u001b[0m     check_consistent_length(y_pred, y_true, sample_weight)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    935\u001b[0m         )\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    s = score(solution[solution.fold_id == i].copy(), submission[solution.fold_id == i].copy(), \"row_id\", 1)\n",
    "    print(f\"Score {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[submission.normal_mild == 1/3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coord_df = pd.read_csv(\"train_coord_df.csv\")\n",
    "mask = solution.study_id.isin(train_coord_df.study_id)\n",
    "solution = solution[mask]\n",
    "submission = submission[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = score(solution.sort_values(\"row_id\", ascending=False).copy(), submission.sort_values(\"row_id\", ascending=True).copy(), \"row_id\", 1)\n",
    "f\"Score {s}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    s = score(solution[solution.fold_id == i].copy(), submission[solution.fold_id == i].copy(), \"row_id\", 1)\n",
    "    print(f\"Score {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "axial_keypoints_df = pd.read_csv(\"axial_keypoints_df.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
